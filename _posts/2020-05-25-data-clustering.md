---
title: Telegram Data Clustering Contest
date: 2020-05-25
minutes: 9
author: Rustem G
---

Завершился второй раунд [соревнования по кластеризации данных](https://contest.com/docs/data_clustering2/ru) от Telegram.
На хакатоне предлагалось разработать алгоритмы для группировки новостей на
русском и английском языках в сюжеты и категории. Здесь я опишу наш подход
к решению поставленных задач.

### Что нужно было сделать?

В целом, решение конкурса выглядит как агрегатор новостей.
Telegram предоставил множество статей из разных источников, написанных
на десятках языках. На первом этапе предлагалось разработать пять алгоритмов:
1. Определение языка и выделение только русских и английских статей.
2. Отделить новостные статьи от блогов и других аналитических статей-рассуждений.
3. Классифицировать новости на семь категорий: общество, спорт, технологии, экономика, развлечения, наука и другие.
4. Сгруппировать схожие новости в сюжеты.
5. Проранжировать сюжеты от наиболее важных к менее важным.

На втором этапе необходимо было поднять http-сервер для индексация новых статей
и вывода результатов.

Большое внимание уделялось не только точности алгоритмов, но и скорости
обработки большого количества статей, что отразилось на выборе алгоритмов.

### Как это можно было сделать?

#### 1. Определение языка

Для определения языка новости не было необходимости обучать собственную модель,
так как можно найти пред-обученные модели с высокой точностью. После оценки
нескольких алгоритмов наш выбор пал на [fasttext](https://fasttext.cc/docs/en/language-identification.html), который показывал точность на уровне **99.5%** и скоростью
**30 миллисекунд** на 1000 статей.

|Сегмент текста|Точность|Скорость|
|---|---|---|
|Заголовок|99.16%|14мс/1000|
|Заголовок + анонс|**99.45%**|**30мс/1000**|
|Полный текст статьи|99.32%|218мс/1000|


#### 2. Новости

На данном шаге мы решили разметить собственный небольшой набор данных для
выбора финального алгоритма, а для обучения мы использовали доступные датасеты
с новостями и блогами. Учитывая необходимость высокой скорости для нас было
важно определять новости только по заголовкам и без использования
тяжелых моделей.

Таким образом, мы протестировали несколько подходов с представлением текста
(мешок слов, Tf-Idf и просто частота использования частей речи) и
обучением легковесных моделей байесовским методом, логистической регресией и
линейный SVM. Выбранные модели представлены в таблице:

|Язык|Сегмент текста|Пред-обработка текста|Векторное представление|Алгоритм|Точность|Скорость|
|---|---|---|---|---|---|---|
|русский|заголовок|части речи|частота использования|Logistic Regression|89%|2мс/1000|
|английский|заголовок|-|tf-idf|Complement Naive Bayes|72%|<1мс/1000|


Одни и те же методы показывают меньшую точность на английском языке, что,
вероятно, исходит из неоднозначности заголовков, которые часто не дают
четкого представления того, что будет описано в статье. Примеры определения новостей по заголовкам:

| Примеры новостей     | Примеры не новостей |
| :------------- | :------------- |
| <img src="/assets/images/ru_news.png"> | <img src="/assets/images/ru_not_news.png"> |
| <img src="/assets/images/en_news.png"> | <img src="/assets/images/en_not_news.png"> |

#### 3. Категории

Так же, как и с определением новостей, здесь мы использовали собственную
разметку для выбора алгоритма и внешние наборы данных для обучения. Не во всех внешних источниках категории
совпадали с целевыми для соревнования, поэтому пришлось дополнительно потрудиться
над исправлением разметки категорий.

Для классификации категорий уже недостаточно было использовать только заголовки -
поэтому мы векторизовали весь текст статьи, а также для увеличения точности
произвели нормализацию слов (лемматизация), чтобы, к примеру, слова _"красивые"_ и _"красивая"_ имели одно значние _"красивый"_. Обучали те же самые классификаторы, как и на предыдущем шаге. Лучшие модели:

|Язык|Сегмент текста|Пред-обработка текста|Векторное представление|Алгоритм|Точность|Скорость|
|---|---|---|---|---|---|---|
|русский|полный текст|лемматизация|tf-idf|Logistic Regression|86%|29мс/1000|
|английский|заголовок|лемматизация|tf-idf|Logistic Regression|75%|33мс/1000|


Снова результаты на английском языке заметно хуже. Возможно это связано с тем,
что статьи на английском языке часто относятся более чем к одной категории и
модель ошибается чаще. Примеры слов наиболее значимых слов для каждой категории:

| Категории на русском     | Категории на английском     |
| :------------- | :------------- |
|  <img src="/assets/images/ru_category.gif">    |  <img src="/assets/images/en_category.gif">    |

#### 4. Сюжеты
В отличии от классификаций на категории или определения новостей, для
кластеризации новостей в сюжеты невозможно обучить модели заранее, так как каждый
день мы видим новые темы в новостях. Высокая связанность новостей в сюжеты могла
быть достигнута только в случае кластеризации новостей "на лету", т.е. во время
обработки большого количества статей.

Векторное представление текста такое же, как и во время классификации категорий. Далее каждая новость представляет из себя отдельную группу и с помощью алгоритма иерархической кластеризации мы последовательно объединяем
маленькие группы в группы побольше, начиная с самых схожих по составу слов. Как только не остается достаточно схожих групп, процесс останавливается.

| Пример результатов кластеризации    |
| :------------- |
| <img src="/assets/images/ru_clusters.gif">     |
| <img src="/assets/images/en_clusters.gif">     |

#### 5. Ранжирование сюжетов

Далее было необходимо проранжировать сюжеты, чтобы наиболее важные темы отражались первыми. Данную задачу не совсем тривиально решать с помощью машинного обучения, потому что важность новостей - достаточно субъективная оценка, которая будет отличаться для людей с разными интересами, из разных регионов или
в разные дни недели.

Так, при решении это задачи мы положились на довольно распространный метод **RFM** (Recency, Frequency, Monetary), используемый для оценки клиентской аудитории:
- В качестве _Recency_ мы использовали среднюю схожесть новостей внутри сюжета, отдавая больший приоритет более связанным сюжетам;
- _Frequency_ - количество статей в сюжете, очевидно, что о важных событиях пишут чаще;
- а для _Monetary_ мы оценивали количество источников, которые пишут о каком-то событии, делая упор на то, что, если о чем-то пишут несколько изданий, такие сюжеты имеют больший вес.

| Результаты сортировки сюжетов    |
| :------------- |
| <img src="/assets/images/ru_top_threads.png">     |
| <img src="/assets/images/en_top_threads.png">     |

### Заключение

Пока мы ждем результатов хакатона, хочется отметить, что большинство задач
решались достаточно простыми, но действенными методами. Использованные алгоритмы векторизации и классификации текста существуют
уже не один десяток лет, притом дают нам высокую скорость и приемлемый уровень
точности. Для других сценариев использования этих моделей возможно использование
более сложных алгоритмов для достижения еще большей точности.

### Ссылки на датасеты

- [русские новости](https://tatianashavrina.github.io/taiga_site/)
- английкие новости: [bbc](http://mlg.ucd.ie/datasets/bbc.html),
[uci агрегатор](http://archive.ics.uci.edu/ml/datasets/News+Aggregator)
- [английские блоги](https://datasetsearch.research.google.com/search?query=blogs&docid=FnbiRu3%2FpKaqhB5aAAAAAA%3D%3D)
